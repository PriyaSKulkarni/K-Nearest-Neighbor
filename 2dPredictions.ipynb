{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FrOstj-JLplD",
        "outputId": "ab385020-5a54-431b-bf5f-dd20bc279d8e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "                 height            diameter             weight  \\\n",
            "0      0.12493777936236    0.13190375787948   0.38616824929558   \n",
            "1      0.14492137354649    0.12500746617994               0.75   \n",
            "2     0.071892497830642                0.03    0.1631761874001   \n",
            "3     0.084260612354435   0.037681879898677   0.23151165834924   \n",
            "4                  0.07   0.090347950123449   0.19177699658224   \n",
            "..                  ...                 ...                ...   \n",
            "115    0.15324808700145     0.1301638325634   0.40118457408591   \n",
            "116    0.12021522833926    0.11607358210855   0.33882777489585   \n",
            "117    0.07556917126148   0.072067954099429   0.16160560001853   \n",
            "118    0.13137129130651   0.091788907990009    0.2781412506351   \n",
            "119    0.12825404991764    0.14820139358115   0.45533536592389   \n",
            "\n",
            "                   hue      class  \n",
            "0      2.9517669794008   Plastic   \n",
            "1      3.4378755151121   Ceramic   \n",
            "2      4.0521528606463   Plastic   \n",
            "3      6.2831853071796   Ceramic   \n",
            "4      2.1255038511543   Plastic   \n",
            "..                 ...        ...  \n",
            "115    2.1792391626888   Plastic   \n",
            "116   0.87686630388415   Plastic   \n",
            "117    3.3382783895954   Plastic   \n",
            "118    2.3833925805427   Plastic   \n",
            "119    2.6866075609372   Plastic   \n",
            "\n",
            "[120 rows x 5 columns]\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "import collections\n",
        "# I have used my google drive to load the training and testing data\n",
        "# Upload the dataset file in your google drive and change the path to run the below line\n",
        "data=pd.read_csv('/content/drive/MyDrive/ML/Priyadataset2c.csv',dtype='object')\n",
        "print(data)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# the manhattan distance is been calculated in this function\n",
        "def Manhattan_function(testdata, datas):\n",
        "    test1=testdata.astype('float64')\n",
        "    data1=datas.astype('float64')\n",
        "    absolute = np.abs(test1 - data1)\n",
        "    difference = np.sum((absolute),axis=1)\n",
        "    Final_diff = np.power(difference, 0.5)\n",
        "    return Final_diff"
      ],
      "metadata": {
        "id": "bR8KgJnm4md9"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The classification of the correct labels are been done in this function\n",
        "# if the knn classifer doesnt come with the majority decision for k=3 and 5, i have classified as ambiguous.\n",
        "# for examaple : for k =3 if knn classifier classify it as 1 plastic 1 metal 1 cermaic: \n",
        "# Since there isnt any majority decision to make, I have declared it as ambiguous\n",
        "def classify(k, label):\n",
        "    #print(k)\n",
        "    output = label[:k]\n",
        "    metal = np.count_nonzero(output == ' Metal ')\n",
        "    plastic = np.count_nonzero(output == ' Plastic ')\n",
        "    ceramic = np.count_nonzero(output == ' Ceramic ')\n",
        "    #print(metal)\n",
        "    #print(plastic)\n",
        "    #print(ceramic)\n",
        "    if metal > plastic and metal > ceramic:\n",
        "        return ' Metal '\n",
        "    elif plastic > metal and plastic > ceramic:\n",
        "        return ' Plastic '\n",
        "    elif ceramic > metal and ceramic > plastic:\n",
        "        return ' Ceramic '\n",
        "    else:\n",
        "      return ' ambiguous'"
      ],
      "metadata": {
        "id": "VUAIp3w-4nT3"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# this function defines the knn classification by finding the distance and sorting it. \n",
        "# this functions calls classify function to classify labels\n",
        "def knn(testsample, k, data):\n",
        "    data1 = data.drop(['class'], axis = 1)\n",
        "    dataset = data1.values\n",
        "    labels = data['class'].values\n",
        "    distance = Manhattan_function(testsample, dataset)\n",
        "    #print(distance)\n",
        "    final_distance = np.vstack((distance, labels))\n",
        "    final = final_distance.T[:, 0].argsort()\n",
        "    final_sorted_distance = final_distance.T[final]\n",
        "    #print(final_sorted_distance)\n",
        "    final_sorted_labels = final_sorted_distance.T[1]\n",
        "    #print(final_sorted_labels)\n",
        "    return classify(k,final_sorted_labels)"
      ],
      "metadata": {
        "id": "1wO_B3L24nf5"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# taking test data as csv input \n",
        "kvalues = 1, 3, 5\n",
        "def main():\n",
        "    for k in kvalues:\n",
        "        predictions = 0\n",
        "        for i, testsample in data.iterrows():\n",
        "            sample = testsample.values[:4]\n",
        "            endresult = testsample.values[4]\n",
        "            dataa = data.drop(i)\n",
        "            predict = knn(sample, k, dataa)\n",
        "            if predict == endresult:\n",
        "                predictions += 1\n",
        "        print(f\"KNN for k value:{k}\")\n",
        "        print(f\"{predictions}/{data.shape[0]} correct predictions using all features\")\n",
        "        print(f'performance is : ', (predictions/data.shape[0]) * 100)\n",
        "        print()"
      ],
      "metadata": {
        "id": "esVkP5m8Luu1"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D6b_A_H4L_Pt",
        "outputId": "0d404030-ef18-490c-b820-373fe63bdfd7"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KNN for k value:1\n",
            "74/120 correct predictions using all features\n",
            "performance is :  61.66666666666667\n",
            "\n",
            "KNN for k value:3\n",
            "60/120 correct predictions using all features\n",
            "performance is :  50.0\n",
            "\n",
            "KNN for k value:5\n",
            "47/120 correct predictions using all features\n",
            "performance is :  39.166666666666664\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "When we compare the predictions for 2c (which use cartesian function) and 2d (which use manhattan function),\n",
        "\n",
        "Both give similar results, there isnt much difference in there performance"
      ],
      "metadata": {
        "id": "COTYh4LeM3yO"
      }
    }
  ]
}